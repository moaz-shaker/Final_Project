{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 - Data Preprocessing and Cleaning\n",
        "\n",
        "This notebook covers:\n",
        "1. Loading the Heart Disease UCI dataset\n",
        "2. Exploratory Data Analysis (EDA)\n",
        "3. Handling missing values\n",
        "4. Data encoding and scaling\n",
        "5. Data visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Heart Disease UCI dataset\n",
        "print(\"Loading Heart Disease UCI dataset...\")\n",
        "heart_disease = fetch_ucirepo(id=45)\n",
        "\n",
        "# Extract features and target\n",
        "X = heart_disease.data.features\n",
        "y = heart_disease.data.targets\n",
        "\n",
        "# Display metadata\n",
        "print(\"\\nDataset Metadata:\")\n",
        "print(heart_disease.metadata)\n",
        "\n",
        "# Display variable information\n",
        "print(\"\\nVariable Information:\")\n",
        "print(heart_disease.variables)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine features and target into a single DataFrame\n",
        "df = pd.concat([X, y], axis=1)\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nBasic Statistics:\")\n",
        "print(df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"Missing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Check data types\n",
        "print(\"\\nData Types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# Check unique values in each column\n",
        "print(\"\\nUnique Values per Column:\")\n",
        "for col in df.columns:\n",
        "    print(f\"{col}: {df[col].nunique()} unique values\")\n",
        "    if df[col].nunique() < 20:  # Show values if less than 20 unique\n",
        "        print(f\"  Values: {sorted(df[col].unique())}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exploratory Data Analysis - Visualizations\n",
        "\n",
        "# 1. Target variable distribution\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "plt.subplot(2, 3, 1)\n",
        "df['target'].value_counts().plot(kind='bar', color=['skyblue', 'lightcoral'])\n",
        "plt.title('Target Variable Distribution')\n",
        "plt.xlabel('Heart Disease (0=No, 1=Yes)')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "# 2. Age distribution\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.hist(df['age'], bins=20, color='lightgreen', alpha=0.7, edgecolor='black')\n",
        "plt.title('Age Distribution')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# 3. Sex distribution\n",
        "plt.subplot(2, 3, 3)\n",
        "df['sex'].value_counts().plot(kind='bar', color=['pink', 'lightblue'])\n",
        "plt.title('Sex Distribution')\n",
        "plt.xlabel('Sex (0=Female, 1=Male)')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "# 4. Chest pain type distribution\n",
        "plt.subplot(2, 3, 4)\n",
        "df['cp'].value_counts().plot(kind='bar', color='orange')\n",
        "plt.title('Chest Pain Type Distribution')\n",
        "plt.xlabel('Chest Pain Type')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "# 5. Resting blood pressure\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.hist(df['trestbps'], bins=20, color='lightcoral', alpha=0.7, edgecolor='black')\n",
        "plt.title('Resting Blood Pressure Distribution')\n",
        "plt.xlabel('Resting Blood Pressure (mm Hg)')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# 6. Cholesterol distribution\n",
        "plt.subplot(2, 3, 6)\n",
        "plt.hist(df['chol'], bins=20, color='lightyellow', alpha=0.7, edgecolor='black')\n",
        "plt.title('Cholesterol Distribution')\n",
        "plt.xlabel('Serum Cholesterol (mg/dl)')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation Analysis\n",
        "plt.figure(figsize=(12, 10))\n",
        "correlation_matrix = df.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
        "plt.title('Correlation Matrix of Heart Disease Dataset')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Top correlations with target variable\n",
        "target_corr = correlation_matrix['target'].abs().sort_values(ascending=False)\n",
        "print(\"Top correlations with target variable:\")\n",
        "print(target_corr[1:])  # Exclude target itself\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Box plots for numerical features by target\n",
        "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, feature in enumerate(numerical_features, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    sns.boxplot(data=df, x='target', y=feature)\n",
        "    plt.title(f'{feature} by Heart Disease')\n",
        "    plt.xlabel('Heart Disease (0=No, 1=Yes)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Preprocessing Steps\n",
        "\n",
        "# 1. Handle missing values (if any)\n",
        "print(\"Missing values before preprocessing:\")\n",
        "print(df.isnull().sum().sum())\n",
        "\n",
        "# 2. Create a copy for preprocessing\n",
        "df_processed = df.copy()\n",
        "\n",
        "# 3. Handle any potential missing values (replace with median for numerical, mode for categorical)\n",
        "for col in df_processed.columns:\n",
        "    if df_processed[col].dtype in ['int64', 'float64']:\n",
        "        df_processed[col].fillna(df_processed[col].median(), inplace=True)\n",
        "    else:\n",
        "        df_processed[col].fillna(df_processed[col].mode()[0], inplace=True)\n",
        "\n",
        "print(\"Missing values after preprocessing:\")\n",
        "print(df_processed.isnull().sum().sum())\n",
        "\n",
        "# 4. Separate features and target\n",
        "X = df_processed.drop('target', axis=1)\n",
        "y = df_processed['target']\n",
        "\n",
        "print(f\"\\nFeatures shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Feature scaling\n",
        "# For this dataset, most features are already in appropriate ranges, but we'll apply StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "print(\"Feature scaling completed using StandardScaler\")\n",
        "print(f\"Scaled features shape: {X_scaled.shape}\")\n",
        "\n",
        "# Display scaled features statistics\n",
        "print(\"\\nScaled features statistics:\")\n",
        "print(X_scaled.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train-test split completed:\")\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "print(f\"Training target distribution: {y_train.value_counts().to_dict()}\")\n",
        "print(f\"Test target distribution: {y_test.value_counts().to_dict()}\")\n",
        "\n",
        "# Save the processed data\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs('../data', exist_ok=True)\n",
        "os.makedirs('../models', exist_ok=True)\n",
        "\n",
        "# Save processed data\n",
        "joblib.dump(X_train, '../data/X_train.pkl')\n",
        "joblib.dump(X_test, '../data/X_test.pkl')\n",
        "joblib.dump(y_train, '../data/y_train.pkl')\n",
        "joblib.dump(y_test, '../data/y_test.pkl')\n",
        "joblib.dump(scaler, '../models/scaler.pkl')\n",
        "\n",
        "print(\"\\nProcessed data saved successfully!\")\n",
        "print(\"Files saved:\")\n",
        "print(\"- ../data/X_train.pkl\")\n",
        "print(\"- ../data/X_test.pkl\") \n",
        "print(\"- ../data/y_train.pkl\")\n",
        "print(\"- ../data/y_test.pkl\")\n",
        "print(\"- ../models/scaler.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Box plots for numerical features by target\n",
        "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, feature in enumerate(numerical_features, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    sns.boxplot(data=df, x='target', y=feature)\n",
        "    plt.title(f'{feature} by Heart Disease')\n",
        "    plt.xlabel('Heart Disease (0=No, 1=Yes)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
