{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 - Feature Selection\n",
        "\n",
        "This notebook covers:\n",
        "1. Loading preprocessed data\n",
        "2. Feature importance using Random Forest\n",
        "3. Recursive Feature Elimination (RFE)\n",
        "4. Chi-Square test for feature significance\n",
        "5. Comparing different feature selection methods\n",
        "6. Selecting optimal features for modeling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import RFE, SelectKBest, chi2, f_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load preprocessed data\n",
        "print(\"Loading preprocessed data...\")\n",
        "X_train = joblib.load('../data/X_train.pkl')\n",
        "X_test = joblib.load('../data/X_test.pkl')\n",
        "y_train = joblib.load('../data/y_train.pkl')\n",
        "y_test = joblib.load('../data/y_test.pkl')\n",
        "\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Test data shape: {X_test.shape}\")\n",
        "print(f\"Feature names: {list(X_train.columns)}\")\n",
        "\n",
        "# Display first few rows\n",
        "print(\"\\nFirst 5 rows of training data:\")\n",
        "print(X_train.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method 1: Random Forest Feature Importance\n",
        "print(\"Method 1: Random Forest Feature Importance\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Train Random Forest to get feature importance\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': rf.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"Feature Importance (Random Forest):\")\n",
        "print(feature_importance)\n",
        "\n",
        "# Visualize feature importance\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.barh(range(len(feature_importance)), feature_importance['importance'], \n",
        "         color='skyblue', alpha=0.7, edgecolor='black')\n",
        "plt.yticks(range(len(feature_importance)), feature_importance['feature'])\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.title('Random Forest Feature Importance')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Select top features based on importance\n",
        "top_features_rf = feature_importance.head(8)['feature'].tolist()\n",
        "print(f\"\\nTop 8 features selected by Random Forest: {top_features_rf}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method 2: Recursive Feature Elimination (RFE)\n",
        "print(\"\\nMethod 2: Recursive Feature Elimination (RFE)\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Use Logistic Regression as base estimator for RFE\n",
        "estimator = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# Apply RFE to select top 8 features\n",
        "rfe = RFE(estimator=estimator, n_features_to_select=8)\n",
        "rfe.fit(X_train, y_train)\n",
        "\n",
        "# Get selected features\n",
        "selected_features_rfe = X_train.columns[rfe.support_].tolist()\n",
        "feature_ranking_rfe = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'ranking': rfe.ranking_,\n",
        "    'selected': rfe.support_\n",
        "}).sort_values('ranking')\n",
        "\n",
        "print(\"RFE Feature Ranking:\")\n",
        "print(feature_ranking_rfe)\n",
        "\n",
        "print(f\"\\nTop 8 features selected by RFE: {selected_features_rfe}\")\n",
        "\n",
        "# Visualize RFE results\n",
        "plt.figure(figsize=(12, 8))\n",
        "colors = ['red' if not selected else 'green' for selected in rfe.support_]\n",
        "plt.barh(range(len(feature_ranking_rfe)), feature_ranking_rfe['ranking'], \n",
        "         color=colors, alpha=0.7, edgecolor='black')\n",
        "plt.yticks(range(len(feature_ranking_rfe)), feature_ranking_rfe['feature'])\n",
        "plt.xlabel('RFE Ranking (1 = selected)')\n",
        "plt.title('Recursive Feature Elimination Results')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method 3: Statistical Tests (F-test and Chi-Square)\n",
        "print(\"\\nMethod 3: Statistical Tests\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# F-test (ANOVA F-test)\n",
        "f_selector = SelectKBest(score_func=f_classif, k=8)\n",
        "X_train_f = f_selector.fit_transform(X_train, y_train)\n",
        "selected_features_f = X_train.columns[f_selector.get_support()].tolist()\n",
        "\n",
        "f_scores = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'f_score': f_selector.scores_,\n",
        "    'p_value': f_selector.pvalues_,\n",
        "    'selected': f_selector.get_support()\n",
        "}).sort_values('f_score', ascending=False)\n",
        "\n",
        "print(\"F-test Results:\")\n",
        "print(f_scores)\n",
        "\n",
        "print(f\"\\nTop 8 features selected by F-test: {selected_features_f}\")\n",
        "\n",
        "# Visualize F-test results\n",
        "plt.figure(figsize=(12, 8))\n",
        "colors = ['red' if not selected else 'green' for selected in f_selector.get_support()]\n",
        "plt.barh(range(len(f_scores)), f_scores['f_score'], \n",
        "         color=colors, alpha=0.7, edgecolor='black')\n",
        "plt.yticks(range(len(f_scores)), f_scores['feature'])\n",
        "plt.xlabel('F-Score')\n",
        "plt.title('F-test Feature Selection Results')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare all feature selection methods\n",
        "print(\"\\nFeature Selection Comparison\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Create comparison DataFrame\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'RF_Importance': feature_importance.set_index('feature')['importance'],\n",
        "    'RFE_Selected': [1 if f in selected_features_rfe else 0 for f in X_train.columns],\n",
        "    'F_Test_Selected': [1 if f in selected_features_f else 0 for f in X_train.columns]\n",
        "})\n",
        "\n",
        "# Calculate consensus score\n",
        "comparison_df['Consensus_Score'] = (\n",
        "    comparison_df['RFE_Selected'] + \n",
        "    comparison_df['F_Test_Selected'] + \n",
        "    (comparison_df['RF_Importance'] > comparison_df['RF_Importance'].median()).astype(int)\n",
        ")\n",
        "\n",
        "# Sort by consensus score\n",
        "comparison_df = comparison_df.sort_values('Consensus_Score', ascending=False)\n",
        "\n",
        "print(\"Feature Selection Comparison:\")\n",
        "print(comparison_df)\n",
        "\n",
        "# Select final features based on consensus\n",
        "final_features = comparison_df[comparison_df['Consensus_Score'] >= 2]['Feature'].tolist()\n",
        "print(f\"\\nFinal selected features (consensus >= 2): {final_features}\")\n",
        "\n",
        "# If we need exactly 8 features, take top 8 by consensus\n",
        "if len(final_features) > 8:\n",
        "    final_features = final_features[:8]\n",
        "elif len(final_features) < 8:\n",
        "    # Add features with highest RF importance that aren't already selected\n",
        "    remaining_features = comparison_df[comparison_df['Consensus_Score'] < 2]['Feature'].tolist()\n",
        "    needed = 8 - len(final_features)\n",
        "    final_features.extend(remaining_features[:needed])\n",
        "\n",
        "print(f\"\\nFinal 8 features for modeling: {final_features}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create datasets with selected features\n",
        "X_train_selected = X_train[final_features]\n",
        "X_test_selected = X_test[final_features]\n",
        "\n",
        "print(f\"Original training data shape: {X_train.shape}\")\n",
        "print(f\"Selected training data shape: {X_train_selected.shape}\")\n",
        "print(f\"Features removed: {X_train.shape[1] - X_train_selected.shape[1]}\")\n",
        "\n",
        "# Visualize final feature selection\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# 1. Consensus score visualization\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.barh(range(len(comparison_df)), comparison_df['Consensus_Score'], \n",
        "         color='lightblue', alpha=0.7, edgecolor='black')\n",
        "plt.yticks(range(len(comparison_df)), comparison_df['Feature'])\n",
        "plt.xlabel('Consensus Score')\n",
        "plt.title('Feature Selection Consensus')\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# 2. Selected vs not selected\n",
        "plt.subplot(1, 3, 2)\n",
        "selected_mask = [f in final_features for f in comparison_df['Feature']]\n",
        "colors = ['green' if selected else 'red' for selected in selected_mask]\n",
        "plt.barh(range(len(comparison_df)), [1] * len(comparison_df), \n",
        "         color=colors, alpha=0.7, edgecolor='black')\n",
        "plt.yticks(range(len(comparison_df)), comparison_df['Feature'])\n",
        "plt.xlabel('Selected (Green) vs Not Selected (Red)')\n",
        "plt.title('Final Feature Selection')\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# 3. Feature importance of selected features\n",
        "plt.subplot(1, 3, 3)\n",
        "selected_importance = comparison_df[comparison_df['Feature'].isin(final_features)]\n",
        "plt.barh(range(len(selected_importance)), selected_importance['RF_Importance'], \n",
        "         color='orange', alpha=0.7, edgecolor='black')\n",
        "plt.yticks(range(len(selected_importance)), selected_importance['Feature'])\n",
        "plt.xlabel('Random Forest Importance')\n",
        "plt.title('Importance of Selected Features')\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save feature-selected data and feature selection results\n",
        "import os\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs('../data', exist_ok=True)\n",
        "os.makedirs('../models', exist_ok=True)\n",
        "\n",
        "# Save feature-selected data\n",
        "joblib.dump(X_train_selected, '../data/X_train_selected.pkl')\n",
        "joblib.dump(X_test_selected, '../data/X_test_selected.pkl')\n",
        "joblib.dump(final_features, '../models/selected_features.pkl')\n",
        "\n",
        "# Save feature selection models and results\n",
        "joblib.dump(rf, '../models/rf_feature_selector.pkl')\n",
        "joblib.dump(rfe, '../models/rfe_selector.pkl')\n",
        "joblib.dump(f_selector, '../models/f_test_selector.pkl')\n",
        "joblib.dump(comparison_df, '../models/feature_comparison.pkl')\n",
        "\n",
        "print(\"Feature selection completed and data saved!\")\n",
        "print(\"Files saved:\")\n",
        "print(\"- ../data/X_train_selected.pkl\")\n",
        "print(\"- ../data/X_test_selected.pkl\")\n",
        "print(\"- ../models/selected_features.pkl\")\n",
        "print(\"- ../models/rf_feature_selector.pkl\")\n",
        "print(\"- ../models/rfe_selector.pkl\")\n",
        "print(\"- ../models/f_test_selector.pkl\")\n",
        "print(\"- ../models/feature_comparison.pkl\")\n",
        "\n",
        "# Display summary\n",
        "print(f\"\\nFeature Selection Summary:\")\n",
        "print(f\"- Original features: {X_train.shape[1]}\")\n",
        "print(f\"- Selected features: {len(final_features)}\")\n",
        "print(f\"- Features removed: {X_train.shape[1] - len(final_features)}\")\n",
        "print(f\"- Dimensionality reduction: {((X_train.shape[1] - len(final_features)) / X_train.shape[1] * 100):.1f}%\")\n",
        "print(f\"- Selected features: {final_features}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
